<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://learnableloop.ai/feed.xml" rel="self" type="application/atom+xml" /><link href="https://learnableloop.ai/" rel="alternate" type="text/html" /><updated>2022-02-05T10:01:41-06:00</updated><id>https://learnableloop.ai/feed.xml</id><title type="html">Kobus Esterhuysen â€” Data Science Blog</title><subtitle>Data Science Blog</subtitle><entry><title type="html">Temporal Difference 4: Control with Q-Learning in Reinforcement Learning</title><link href="https://learnableloop.ai/reinforcement_learning/td/q_learning/openai/gym/2022/02/04/TDControl_Qlearning_WindyGridworld.html" rel="alternate" type="text/html" title="Temporal Difference 4: Control with Q-Learning in Reinforcement Learning" /><published>2022-02-04T00:00:00-06:00</published><updated>2022-02-04T00:00:00-06:00</updated><id>https://learnableloop.ai/reinforcement_learning/td/q_learning/openai/gym/2022/02/04/TDControl_Qlearning_WindyGridworld</id><author><name></name></author><category term="Reinforcement_Learning" /><category term="TD" /><category term="Q_Learning" /><category term="OpenAI" /><category term="Gym" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://learnableloop.ai/images/TDControl_Qlearning_WindyGridworld.png" /><media:content medium="image" url="https://learnableloop.ai/images/TDControl_Qlearning_WindyGridworld.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Temporal Difference 3: Control with Sarsa in Reinforcement Learning</title><link href="https://learnableloop.ai/reinforcement_learning/td/sarsa/openai/gym/2022/02/03/TDControl_Sarsa_WindyGridworld.html" rel="alternate" type="text/html" title="Temporal Difference 3: Control with Sarsa in Reinforcement Learning" /><published>2022-02-03T00:00:00-06:00</published><updated>2022-02-03T00:00:00-06:00</updated><id>https://learnableloop.ai/reinforcement_learning/td/sarsa/openai/gym/2022/02/03/TDControl_Sarsa_WindyGridworld</id><author><name></name></author><category term="Reinforcement_Learning" /><category term="TD" /><category term="Sarsa" /><category term="OpenAI" /><category term="Gym" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://learnableloop.ai/images/TDControl_Sarsa_WindyGridworld.png" /><media:content medium="image" url="https://learnableloop.ai/images/TDControl_Sarsa_WindyGridworld.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Temporal Difference 2: Estimation of the Action-value Function in Reinforcement Learning</title><link href="https://learnableloop.ai/reinforcement_learning/td/openai/gym/2022/02/02/TDPrediction_Sarsa_WindyGridworld.html" rel="alternate" type="text/html" title="Temporal Difference 2: Estimation of the Action-value Function in Reinforcement Learning" /><published>2022-02-02T00:00:00-06:00</published><updated>2022-02-02T00:00:00-06:00</updated><id>https://learnableloop.ai/reinforcement_learning/td/openai/gym/2022/02/02/TDPrediction_Sarsa_WindyGridworld</id><author><name></name></author><category term="Reinforcement_Learning" /><category term="TD" /><category term="OpenAI" /><category term="Gym" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://learnableloop.ai/images/TDPrediction_Sarsa_WindyGridworld.png" /><media:content medium="image" url="https://learnableloop.ai/images/TDPrediction_Sarsa_WindyGridworld.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Temporal Difference 1: Estimation of the State-value Function in Reinforcement Learning</title><link href="https://learnableloop.ai/reinforcement_learning/td/openai/gym/2022/02/01/TDPrediction_V_WindyGridworld.html" rel="alternate" type="text/html" title="Temporal Difference 1: Estimation of the State-value Function in Reinforcement Learning" /><published>2022-02-01T00:00:00-06:00</published><updated>2022-02-01T00:00:00-06:00</updated><id>https://learnableloop.ai/reinforcement_learning/td/openai/gym/2022/02/01/TDPrediction_V_WindyGridworld</id><author><name></name></author><category term="Reinforcement_Learning" /><category term="TD" /><category term="OpenAI" /><category term="Gym" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://learnableloop.ai/images/TDPrediction_V_WindyGridworld.png" /><media:content medium="image" url="https://learnableloop.ai/images/TDPrediction_V_WindyGridworld.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Monte Carlo 5: Off-Policy Estimation of the Action-value Function in Reinforcement Learning</title><link href="https://learnableloop.ai/reinforcement_learning/mc/openai/gym/2022/01/26/MCPrediction_OffPolicy_Q.html" rel="alternate" type="text/html" title="Monte Carlo 5: Off-Policy Estimation of the Action-value Function in Reinforcement Learning" /><published>2022-01-26T00:00:00-06:00</published><updated>2022-01-26T00:00:00-06:00</updated><id>https://learnableloop.ai/reinforcement_learning/mc/openai/gym/2022/01/26/MCPrediction_OffPolicy_Q</id><author><name></name></author><category term="Reinforcement_Learning" /><category term="MC" /><category term="OpenAI" /><category term="Gym" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://learnableloop.ai/images/MCPrediction_OffPolicy_Q.png" /><media:content medium="image" url="https://learnableloop.ai/images/MCPrediction_OffPolicy_Q.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>